{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ef945",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_paths = '../datas/recommender_data/'\n",
    "\n",
    "movie = pd.read_csv(recipe_paths + \"recommender system table.csv\" , encoding = 'cp949')\n",
    "# meta = pd.read_csv(movie_paths + 'movies_metadata.csv', low_memory=False)\n",
    "# meta = meta.rename(columns={'id':'movieId'})\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie['member_id'] = movie['member_id'].astype(str)\n",
    "# meta['movieId'] = meta['movieId'].astype(str)\n",
    "\n",
    "# movie = pd.merge(movie, meta[['member_id', 'CKG_NM']], on='movieId')\n",
    "movie['one'] = 1\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movie.pivot_table(index='member_id', columns = 'CKG_NM', values = 'one').fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04304978",
   "metadata": {},
   "outputs": [],
   "source": [
    "watching_metrix = df.iloc[:, : ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경설정\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 조건 설정\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b729de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "  # 데이터 정의\n",
    "  def __init__(self, x_data, y_data = None):\n",
    "    self.x_data = x_data\n",
    "    self.y_data = y_data\n",
    "\n",
    "  # 이 데이터 셋의 총 데이터 수\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 어떠한 idx를 받았을 때 그에 맞는 데이터를 반환\n",
    "  def __getitem__(self, idx):\n",
    "    if self.y_data is None:\n",
    "      x = torch.FloatTensor(self.x_data[idx])\n",
    "      return x\n",
    "    else:\n",
    "      x = torch.FloatTensor(self.x_data[idx])\n",
    "      y = torch.FloatTensor(self.y_data[idx])\n",
    "      return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoder 모델 설계\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.fc1_1 = nn.Linear(4005, 15)\n",
    "        self.fc1_2 = nn.Linear(4005, 15)\n",
    "        self.relu = nn.ReLU()\n",
    "                        \n",
    "    def encode(self, x):\n",
    "        mu = self.relu(self.fc1_1(x))\n",
    "        log_var = self.relu(self.fc1_2(x))\n",
    "                \n",
    "        return mu,log_var\n",
    "    \n",
    "    def reparametrize(self, mu, log_var):\n",
    "        std = log_var.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_().to(DEVICE)\n",
    "        \n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        reparam = self.reparametrize(mu,log_var)\n",
    "        \n",
    "        return mu,log_var,reparam\n",
    "        \n",
    "encoder = Encoder().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe06aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.fc1 = nn.Linear(15, 4005)\n",
    "        self.simoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.simoid(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "decoder = Decoder().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_function = nn.MSELoss(size_average=False)\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(log_var.exp()).mul_(-1).add_(1).add_(log_var)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return MSE + KLD\n",
    "\n",
    "parameters = list(encoder.parameters())+ list(decoder.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1943b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, train_loader):\n",
    "  encoder.train()\n",
    "  decoder.train()\n",
    "  train_loss = 0\n",
    "\n",
    "  for feature in train_loader:\n",
    "\n",
    "    feature = feature.to(DEVICE)\n",
    "    optimizer.zero_grad()\n",
    "    mu,log_var,reparam = encoder(feature)\n",
    "    output = decoder(reparam)\n",
    "    loss = loss_function(output, feature, mu, log_var)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.item()\n",
    "\n",
    "  train_loss /= len(train_loader)\n",
    "  return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, train_loader):\n",
    "  encoder.eval()\n",
    "  decoder.eval()\n",
    "  result = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for feature in train_loader:\n",
    "      feature = feature.to(DEVICE)\n",
    "      mu,log_var,reparam = encoder(feature)\n",
    "      output = decoder(reparam)\n",
    "      result.append(output.cpu().numpy())\n",
    "\n",
    "  result = np.concatenate(result)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60febaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(watching_metrix)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size = BATCH_SIZE,\n",
    "  shuffle = False,\n",
    "  drop_last = False)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "  train_loss = train(encoder, decoder, train_loader)\n",
    "  print(f\"\\n[EPOCH: {epoch}], \\tTrain Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(encoder, decoder, train_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "watching_metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_li = df.columns.tolist()\n",
    "result[watching_metrix >= 1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab550f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_li = []\n",
    "for i in result.argmax(axis=1):\n",
    "  recommend_li.append(movie_li[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_df = pd.DataFrame()\n",
    "recommend_df['user_id'] = df.index.tolist()\n",
    "recommend_df['recipe_name'] = recommend_li\n",
    "recommend_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_df[recommend_df['user_id'] == '7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns.tolist():\n",
    "  if '돼지고기' in i:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504914a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb73d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.iloc[12][df.iloc[12] >= 1].index.tolist():\n",
    "  if '돼지고기' in i:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
